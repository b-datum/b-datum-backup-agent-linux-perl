#!/usr/bin/env perl

# bdatum-backup 
# Copyright (c) 2013 b-datum, http://www.b-datum.com
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

use utf8;
use strict;
use warnings qw(FATAL utf8);
use open qw(:std :utf8);
use Carp;
use Sys::Syslog qw(:standard :macros);

use File::Next;
use File::stat;
use File::Basename;
use File::Copy;
use File::Slurp qw(read_file);
use File::Temp qw/ :seekable tempdir /;
use File::MimeInfo::Magic;
use Fcntl qw(:flock SEEK_END);
use IO::Handle;
use IO::File;
use Digest::MD5::File qw(file_md5_hex);
use Digest::MD5 qw(md5_hex);
use Cwd qw(abs_path);

use Encode;

use LWP::UserAgent::Determined;
use LWP::ConnCache;
use IO::Socket::SSL;
use Net::SSL ();
use URI;
use HTTP::Request::Common qw(GET PUT HEAD POST DELETE);
use HTTP::Request;
use JSON qw(encode_json decode_json);

use Getopt::Long::Descriptive;
use Parallel::ForkManager;
use Try::Tiny;
use DateTime;
use Time::HiRes qw(time);
use Perl6::Junction qw(all);
use List::MoreUtils qw(pairwise);
use Config::Any::INI;

use version; our $VERSION = qv('0.17'); # same line, keep backcompat with older MakeMaker

use constant {
  BASE_URL => $ENV{'BDATUM_BASE_URL'} || 'https://api.b-datum.com',
  LIMIT_PARTS => 10000,

  # file attrs
  MTIME   => 0,
  ETAG    => 1,
  UID     => 2,
  GID     => 3,
  UMASK   => 4,
  SYMLINK => 5
};

# ,=> to avoid fat comma stringification
my %metadata_map = (
  UID
  , => 'meta-uid',
  GID
  , => 'meta-gid',
  UMASK
  ,        => 'meta-umask',
  SYMLINK, => 'meta-symlink',
);

our $b_datum_dir = "$ENV{HOME}/.b-datum";

our ( $node_key, $partner_key, $path, @blacklist, $manifest );
our ( $stage_dir, $configfile, $ua, $pm );
our ( $opt, $usage, $run_lock_fh, $PART_LIMIT_SIZE );

our $parent_pid = $$;
our $_abort     = 0;

$SIG{USR1} = sub {
  $_abort = 1;
};

sub _unauthorized_abort {
  &_log_error("*** ERROR: 401 http unauthorized");
  exit 77;    # EX_NOPERM
}

&setup_manifest;
&run;

sub run {
  while (1) {
    eval { &main; };

    if ($@) {
      &_log_error($@);
    }

    last unless $opt->persistent;
    sleep($opt->persistent_time);
    &check_alive;
  }

  &_remove_lock_running;
}

sub check_alive {
  my $req = GET '/alive';
  my $res = _send_request($req);

  if (!$res->is_success) {
    &_log_warn("WARNING: can't send alive to b-datum");
  }

}

sub _check_already_running {
  my $lock_file = &_make_control_file('lock');
  if ( -f $lock_file ) {
    open( FHL, "<", $lock_file ) or die "Cannot open $lock_file - $!";
    flock( FHL, LOCK_EX | LOCK_NB ) or die "Already running.";
  }
  open( FHL, ">", $lock_file ) or die "Cannot open $lock_file - $!";
  flock( FHL, LOCK_EX | LOCK_NB );
}

sub _remove_lock_running {
  my $lock_file = &_make_control_file('lock');
  unlink($lock_file);
  my $lastbackup_file = &_make_control_file('lastbackup');
  unlink($lastbackup_file) if -e $lastbackup_file;
}

sub setup_manifest {
  $manifest = File::Temp->new( UNLINK => 0, )
    or die q{Couldn't create manifest file};
}

sub _create_local_dir {
  my $dir = shift;
  mkdir($dir) unless -d $dir;
  die "*** ERROR: Can't create directory $dir" unless -d $dir;
  return $dir;
}

sub main {
  ( $opt, $usage ) = describe_options(
    "$0 - %o <some-arg>",
    [ "node_key|n=s"    => 'node key' ],
    [ "partner_key|p=s" => 'partner key' ],
    [ "path=s"          => 'target path' ],
    [],
    [ "nodelete|k" => q{don't remove in remote storage files deleted} ],
    [ "workers|w"  => 'number of workers (default: 5)', { default => 5 } ],
    [ "daemon|d"   => "Daemon mode" ],
    [ "config|c=s" => 'config file' ],
    [ "profile=s"  => 'load profile' ],
    [ "persistent" => 'persistent mode' ],
    [ "persistent_time=i" => 'time in seconds for run again the scan in directory to do backup (default: 180)', { default => 180 } ],
    [ "retry_time=i" => 'time to retry the request to bdatum if some request fails (default: 30)', { default => 30 } ],
    [],
    [ "proxy_scheme=s"   => "Proxy schema (Default: http)" ],
    [ "proxy_server=s"   => "Proxy server" ],
    [ "proxy_username=s" => "Proxy username" ],
    [ "proxy_password=s" => "Proxy password" ],
    [],
    [ "part_size=i" => "Part size in megabytes of multipart upload (default: 5)", { default => 5 } ],
    [],
    [ "verbose|v" => 'verbose mode', ],
    [ "debug"     => 'debug mode' ],
    [ 'help|h', "print usage message and exit" ],
  );

  print( $usage->text ), exit(0) if $opt->help;

  $0 = "[bdatum-backup]";

  # Daemon
  if ($opt->daemon) {
    my $main_pid = fork();
    die "cannot fork" unless defined $main_pid;
    exit 0 if $main_pid != 0;
  }

  # Check part_size
  if ($opt->part_size < 5 or $opt->part_size > 500) {
    &_log_error("part_size option need to be > 5 or < 500.");
    exit(0);
  }

  # part size for multipart upload.
  $PART_LIMIT_SIZE = $opt->part_size * 1024 * 1024;

  # create base dir
  $stage_dir = join( '/', $b_datum_dir, 'stage' );
  &_create_local_dir($b_datum_dir);
  &_create_local_dir($stage_dir);
  $configfile = $opt->config || '/etc/bdatum/backup.conf';

  if ( -r $configfile ) {
    my $st = stat $configfile;
    my $mode = sprintf( '%04o', $st->mode & 07777 );
    if ( $mode ne '0400' ) {
      &_log_error( "Please run 'chmod 0400 $configfile'", 78 );
    }

    my $config_all = Config::Any::INI->load($configfile);
    my $profile    = $opt->profile;

    my $config =
      defined $profile && exists $config_all->{$profile}
      ? $config_all->{$profile}
      : $config_all;

    $node_key    = $config->{node_key};
    $partner_key = $config->{partner_key};
    $path        = $config->{path};
    @blacklist   = map {
      my $r = $config->{blacklist}->{$_};
      eval { qr/$r/ }
        or die qq{Blacklist item "$_" is not a valid regex};
    } keys %{ $config->{blacklist} || {} };
  }

  # skipping staging dir by blacklist
  push( @blacklist, qr/^$b_datum_dir/, qr/^$stage_dir/ );

  # for linux
  push( @blacklist, qr/^\/proc\//, qr/^\/sys\// );

  $node_key    = $opt->node_key    if $opt->node_key;
  $partner_key = $opt->partner_key if $opt->partner_key;
  $path        = $opt->path        if $opt->path;

  if ( !&_validate_key($node_key)
    or !&_validate_key($partner_key)
    or !&_validate_path($path) )
  {
    &_log_error( "Required option missing.", 64 );
  }

  &_log_debug("Node key: $node_key");
  &_log_debug("Partner key: $partner_key");
  &_log_debug("Path: $path");

  &_check_already_running;

  my $ssl_cache = IO::Socket::SSL::Session_Cache->new(10);
  my $context   = IO::Socket::SSL::SSL_Context->new(
    SSL_verify_mode   => 0,
    SSL_session_cache => $ssl_cache
  );
  IO::Socket::SSL::set_default_context($context);
  IO::Socket::SSL::set_default_session_cache($ssl_cache);

  my $ua_cache = LWP::ConnCache->new();
  $ua_cache->total_capacity(10);

  $ua = LWP::UserAgent::Determined->new(
    requests_redirectable => [qw(GET HEAD DELETE PUT POST)],
    agent                 => "bdatum-backup/$VERSION (Linux)",
  );

  if ( $opt->proxy_server ) {
    my $scheme   = $opt->proxy_scheme || 'http';
    my $server   = $opt->proxy_server;
    my $username = $opt->proxy_username;
    my $password = $opt->proxy_password;

    # For HTTP
    my $proxy = "$scheme://$username:$password\@$server";
    $ua->proxy( [$scheme], $proxy );

    # For HTTPS
    $proxy                             = "$scheme://$server";
    $ENV{HTTPS_PROXY}                  = $proxy;
    $ENV{HTTPS_PROXY_USERNAME}         = $username;
    $ENV{HTTPS_PROXY_PASSWORD}         = $password;
    $ENV{HTTP_PROXY}                   = $proxy;
    $ENV{HTTP_PROXY_USERNAME}          = $username;
    $ENV{HTTP_PROXY_PASSWORD}          = $password;
    $Net::HTTPS::SSL_SOCKET_CLASS      = "Net::SSL";
    $ENV{PERL_LWP_SSL_VERIFY_HOSTNAME} = 0;
    $ua->env_proxy(1);

  }

  $ua->ssl_opts( verify_hostname => 0, SSL_verify_mode => 0, )
    if LWP::UserAgent::Determined->can('ssl_opts');
  $ua->timing($opt->retry_time);
  $ua->conn_cache($ua_cache);
  $ua->add_handler( request_prepare =>
      sub { shift->authorization_basic( $node_key, $partner_key ); } );

  if ( $opt->verbose ) {
    $ua->add_handler( "request_send",  sub { shift->dump; return } );
    $ua->add_handler( "response_done", sub { shift->dump; return } );
  }

  $pm = Parallel::ForkManager->new( $opt->workers );

  start();

  $pm->wait_all_children;

  _send_manifest();

  close($manifest);
  unlink($manifest);

  exit(0);
}

sub _get_files {
  return File::Next::everything(
    {
      error_handler => sub { &_log_error( @_ ); },

      # show symlinks
      follow_symlinks => 1,

      # but ignore its descendants in case of being a link to dir
      file_filter => sub {

        -p $File::Next::name
          && _log_warn("SKIPPING: $File::Next::name is a named pipe")
          && return;

        -S $File::Next::name
          && _log_warn("SKIPPING: $File::Next::name is a socket")
          && return;

        -b $File::Next::name
          && _log_warn("SKIPPING: $File::Next::name is a block special file")
          && return;

        -p $File::Next::name
          && _log_warn("SKIPPING: $File::Next::name is a named pipe")
          && return;

        -c $File::Next::name
          && _log_warn(
          "SKIPPING: $File::Next::name is a character special file")
          && return;

        -t $File::Next::name
          && _log_warn("SKIPPING: $File::Next::name is is opened to a tty")
          && return;

             !-R $File::Next::name
          && !-l $File::Next::name
          && _log_warn("SKIPPING: $File::Next::name can't be read")
          && return;

        !_in_blacklist($File::Next::name)
          && !-l dirname($File::Next::name)
          && ( ( -d $File::Next::name && -x $File::Next::name )
          || ( -f $File::Next::name )
          || ( -l $File::Next::name ) );
      },
      descend_filter => sub {
        !-l dirname($File::Next::dir);
      },
    },
    $path
  );
}

sub _validate_key {
  my $key = shift || return 0;
  my $val = $key =~ /^[a-zA-Z0-9]{20}$/ ? 1 : 0;
  &_log_error("The key must be [a-zA-Z0-9]{20} -- $key") unless $val;
  return $val;
}

sub _validate_path {
  my $path = shift || return 0;
  my $val = -d $path and -r $path;
  &_log_error("The directory name is invalid -- $path") unless $val;
  return $val;
}

sub _log {
  my $level = shift;
  my $msg = join( ' ', @_ );
  
  my $syslog_level = LOG_INFO;
  $syslog_level = LOG_DEBUG if $level eq 'debug';
  $syslog_level = LOG_WARNING if $level eq 'warn';
  $syslog_level = LOG_ERR if $level eq 'error';

  openlog($0, 'pid', LOG_USER);
  syslog($syslog_level, "[$level] $msg");
  closelog();

  print "[$level] $msg\n" unless $opt->daemon;
  return 1;
}

sub _log_debug {
  return unless $opt->debug;
  return &_log( 'debug', @_ );
}

sub _log_error {
  my ( $msg, $exit ) = @_;
  &_log( 'error', $msg );
  exit $exit if $exit;
}

sub _log_info {
  return &_log( 'info', @_ );
}

sub _log_warn {
  return &_log( 'warn', @_ );
}

sub is_folder_empty {
  my $dirname = shift;
  opendir(my $dh, $dirname) or die "Not a directory";
  return scalar(grep { $_ ne "." && $_ ne ".." } readdir($dh)) == 0;
}

sub _get_lastbackup {
  my $lastbackup_file = &_make_control_file('lastbackup');
  return unless -e $lastbackup_file;
  my $content = do { local ( @ARGV, $/ ) = $lastbackup_file; <> };
  return $content;
}

sub _write_lastbackup {
    my $file = shift;
    my $lastbackup_file = &_make_control_file('lastbackup');
    open my $fh, '>', $lastbackup_file;
    print $fh $file;
    close $fh;
}

sub start {
  my %cache = _read_cache();

  my $start = DateTime->now( time_zone => 'local' );
  my $files = &_get_files();
  my $lastbackup_file = &_get_lastbackup;
  my $lastbackup_run = $lastbackup_file ? 1 : 0;

FILE: while ( defined( my $file = $files->() ) ) {

    # abort backup if we receive unauthorized response from bdatum.
    _unauthorized_abort() if $_abort;
   
    # fast way to do backup in the "second-first job", 
    # if the first-first backup not finish completely.
    my $cache_file = &_make_control_file('cache');
    if ( ! -e $cache_file && $lastbackup_run ) {
        if ( $lastbackup_file eq $file) { 
            $lastbackup_run = 0;
        }
        next;
    } elsif ( ! -e $cache_file ) {
        &_write_lastbackup($file);
    }

    # here, we go.
    &_log_info("processing: $file");

    if ( -d $file ) {
      $cache{"$file/"} = [];
      if (is_folder_empty($file)) {
         _mkdir($file);
         next;
      }
    }

    next if !-l $file && -d $file;

    my @previous_attrs = @{ $cache{$file} || [] };

    my $change_specs = get_changes( $file, \@previous_attrs );

    $cache{$file} = $change_specs->{attributes};

    # The limit to send a file to bdatum is $PART_LIMIT_SIZE*1000 or 5TB.
    my $file_size = -s $file;
    if ( ($file_size > $PART_LIMIT_SIZE * LIMIT_PARTS) or $file_size > (5*1024*1024*1024*1025)) {
        &_log_error("Skipping $file, because the size ($file_size) is >5TB or >PART_SIZE*10000");
        next;
    }

    &_log_info("Sending $file...");

    {
      $pm->start and next;

      my $attempt = 0;
      my $error;
      do {
        try {
          if ( $previous_attrs[ETAG]
            && ( $previous_attrs[ETAG] eq $change_specs->{attributes}->[ETAG] )
            )
          {

            # no content changed but some metadata did
            if ( @{ $change_specs->{modified_fields} || [] } ) {
              send_patch(%$change_specs);
            }
          }
          else {
            send_file( $file, $change_specs->{attributes}, $change_specs );
          }
        }

        catch { $error = $_; sleep(3); };
        if ($error) {
          &_log_warn("Error sending $file trying again... $attempt");
          &_log_warn("\t\t$error");
        }
      } while ( $error && ( $attempt++ < 3 ) );

      ( unlink( $change_specs->{stage_file} )
          || die
          qq{Could not unlink tempfile "$change_specs->{stage_file}": $!} )
        if exists $change_specs->{stage_file}
        && -e $change_specs->{stage_file}
        && !-l $change_specs->{stage_file};

      $pm->finish;

    }
  }

  $pm->wait_all_children;

  my $end = DateTime->now( time_zone => 'local' );
  &_log_info("*\n*\n*\n* Started: $start");
  &_log_info("* Completed: $end");

  _write_cache(%cache);

}

sub _in_blacklist {
  my $file = shift;
  my $yes = grep { $file =~ $_ } @blacklist;
  _log_warn("SKIPPING: $file is in blacklist") if $yes;
  return $yes;
}

sub get_changes {
  my ( $file, $attrs ) = @_;

  return unless defined $attrs && ( ref $attrs eq 'ARRAY' );
  my $stat = ( -l $file ? File::stat::lstat($file) : File::stat::stat($file) )
    or return;

  my $sfile =
    -l $file
    ? $file
    : _link_to_stage($file);    # no need to move the symlink itself
  my $etag = -l $file ? md5_hex('') : file_md5_hex($sfile);
  my @modified_fields = ();

  my $new_attrs = [
    $stat->mtime, $etag, $stat->uid, $stat->gid,
    sprintf( '%04o', $stat->mode ),
    ( -l $file ? abs_path( readlink $file ) : '' )
  ];

  my $changes = {
    stage_file      => $sfile,
    file            => $file,
    attributes      => $new_attrs,
    modified_fields => undef,
  };

  return $changes unless scalar @$attrs;    # new file, no changes

  push @modified_fields,
    grep { $attrs->[$_] ne $new_attrs->[$_] }
    ( MTIME, ETAG, UID, GID, UMASK, SYMLINK );

  {
    no warnings qw(once);

    # nothing changed
    return $changes
      if all( pairwise { $a eq $b } @$attrs, @$new_attrs ) == 1;
  }

  # symlinks read with readlink get its MTIME changed, we can ignore if
  # the file it's a link
  return $changes
    if -l $file && scalar @$attrs == 1 && defined $attrs->[MTIME];

  $changes->{modified_fields} = [@modified_fields];

  return $changes;

}

sub send_patch {
  my (%change_specs) = @_;

  my $uri = URI->new(BASE_URL);
  $uri->path('storage');

  $uri->query_form(
    path => $change_specs{file},
    map { $metadata_map{$_} => $change_specs{attributes}->[$_] }
      @{ $change_specs{modified_fields} || [] }
  );

  my $req = HTTP::Request->new( 'PATCH', $uri );
  $req->header( ETag => $change_specs{attributes}->[ETAG] );

  _send_request($req);

}

sub send_file {
  my ( $file, $attr ) = @_;

  return _send_default(@_) if -l $file;

  if ( -s $file < $PART_LIMIT_SIZE ) {
    return _send_default(@_);
  }
  else {
    return _send_multipart(@_);
  }

  &_log_info("DONE");

}

sub _send_manifest {
  my $uri = URI->new(BASE_URL);
  $uri->path('storage/manifest');

  my $etag = file_md5_hex( $manifest->filename );

  my $req = PUT $uri,
    Etag    => $etag,
    Content => scalar read_file( $manifest->filename );
  my $res = _send_request($req);
}

sub _send_multipart {
  my ( $file, $attrs, $changes ) = @_;

  my $etag = $attrs->[ETAG];
  &_log_info("init multipart upload to $file");

  my $uri = URI->new(BASE_URL);
  $uri->path('storage');

  return 1
    if _check_duplicate( $uri, $file, $etag, $node_key, $partner_key, $attrs );

  # init
  my $full_etag = $etag;
  my $sfile     = $changes->{stage_file};

  $uri->query_form( path => "$file", multipart => 1 );
  my $req       = POST $uri, Etag => $full_etag;
  my $res       = _send_request($req);
  my $object    = decode_json( $res->content );
  my $upload_id = $object->{upload_id};

  # parts
  my $buffer;

  my $fh = IO::File->new( $sfile, 'r', ':unix' )
    or die "Cannot open $file";

  my $i = 1;
  my @parts;

  while ( read( $fh, $buffer, $PART_LIMIT_SIZE ) ) {
    &log_info("sending part $i of $file");

    my $uri = URI->new(BASE_URL);
    $uri->path('storage');

    my $etag = md5_hex($buffer);

    push @parts, [ $i, $etag ];

    $uri->query_form(
      path      => "$file",
      upload_id => $upload_id,
      part      => $i++
    );

    my $req = PUT $uri,
      Etag    => $etag,
      Content => $buffer;

    my $res = _send_request($req);

    &log_info("finish upload part $i of $file.");
  }
  $fh->close;

  #finalize
  $uri = URI->new(BASE_URL);
  $uri->path('/storage');
  $uri->query_form( path => "$file", upload_id => $upload_id );

  $req = POST $uri,
    Content_type => 'application/json',
    Accept       => 'application/json',
    Etag         => $full_etag,
    Content      => encode_json(
    {
      parts        => \@parts,
      content_type => mimetype($sfile) || 'application/octet-stream',
      _get_metadata( $file, $attrs )
    }
    );
  _send_request($req);
  &_log_info("finish upload multipart to $file");

  _write_to_manifest( $manifest, "+$file\n+${\(-s $sfile)}\n+$full_etag\n\n" );

  return 1;

}

sub _write_to_manifest {
  my ( $manifest_file, $line ) = @_;
  lock($manifest_file);
  print $manifest_file $line;
  unlock($manifest_file);
}

sub _get_metadata {
  my ( $file, $attrs ) = @_;
  map { $metadata_map{$_} => $attrs->[$_] }
    grep { defined $attrs->[$_] && length $attrs->[$_] }
    map { int($_) } keys %metadata_map;
}

sub _mkdir {
  my ( $file, $attrs ) = @_;
  my $uri = URI->new(BASE_URL);

  $file = "$file/";
  &_log_info("$file is an empty dir");

  $uri->path('/storage');

  my $etag = $attrs->[ETAG];

  return 1
    if _check_duplicate( $uri, $file, $etag, $node_key, $partner_key, $attrs );

  my $req = POST $uri,
    Content_Type => 'form-data',
    Content      => [ _get_metadata( $file, $attrs ), path => $file, ];
  _send_request($req);
  return 1;

}

sub _delete {
  my ($file) = @_;
  my $uri = URI->new(BASE_URL);
  $uri->path('storage');
  $uri->query_form( path => $file );
  my $req = DELETE $uri;
  &_log_info("deleting $file");
  my $res = $ua->request($req);

  _write_to_manifest( $manifest, "-$file\n\n" );

  return $res->is_success;
}

sub _send_default {
  my ( $file, $attrs, $changes ) = @_;
  my $uri = URI->new(BASE_URL);
  $uri->path('/storage');

  my $etag = -l $file ? md5_hex('') : $attrs->[ETAG];

  return 1
    if _check_duplicate( $uri, $file, $etag, $node_key, $partner_key, $attrs );

  my $sfile = $changes->{stage_file};

  my $req = POST $uri,
    Content_Type => 'form-data',
    Etag         => $etag,
    Content      => [
    _get_metadata( $file, $attrs ),
    path => "$file",
    ( !-l $file ? ( value => [$sfile] ) : () )
    ];
  _send_request($req);

  my $stat = -l $file ? File::stat::lstat($file) : File::stat::stat($file);
  _write_to_manifest( $manifest, "+$file\n+${\$stat->size}\n+$etag\n\n" );

  return 1;

}

sub _check_duplicate {
  my ( $uri, $file, $etag, $node_key, $partner_key, $attrs ) = @_;
  my $req = POST $uri,
    Content_Type => 'form-data',
    Etag         => $etag,
    Content      => [
    etag  => $etag,
    check => 1,
    path  => "$file",
    _get_metadata( $file, $attrs )
    ];
  my $res = $ua->request($req);
  if ( $res->code == 201 ) {
    my $stat = -l $file ? File::stat::lstat($file) : File::stat::stat($file);
    _write_to_manifest( $manifest, "+$file\n+${\$stat->size}\n+$etag\n\n" );
  }
  return $res->is_success;
}

sub _send_request {

  my $req = shift;
  my $res = $ua->request($req);
  if ( !$res->is_success ) {
    if ( $res->code == 401 ) {
      kill USR1 => $parent_pid;
      exit;
    }
    confess $res->as_string;
  }
  return $res;

}

sub _delete_files {
  my (@to_delete) = @_;
  foreach my $delete_this (@to_delete) {
    $pm->start and next;
    _delete($delete_this);
    $pm->finish;
  }
  $pm->wait_all_children;
}

sub _make_control_file {
  my $suffix = shift;
  my $base   = md5_hex( $node_key . $partner_key . $path );
  return "$b_datum_dir/$base.$suffix";
}

sub _read_cache {
  #
  # Slurp cache File
  #

  my $cache_file = &_make_control_file('cache');
  my %cache;
  my $cache_file_version = &_filename_cache_version($cache_file);

  my $cache_version = &_read_cache_version($cache_file_version);
  if ( version->parse($cache_version) != version->parse($VERSION) ) {
    &_log_info("Remove cache version file: $cache_file_version");
    &_log_info("Remove cache file: $cache_file");
    unlink($cache_file_version);
    unlink($cache_file);
  }

  return () unless -e $cache_file;

  open( my $fh, '<:unix:encoding(UTF-8)', $cache_file )
    or die "Cannot open $cache_file";

  my $t = time;
  my @to_delete;
  while ( my $line = $fh->getline ) {
    chomp($line);
    my $attrs = [ split /,/, $line ];
    my $file  = shift @$attrs;
    chomp($file);
    my $stat  = -l $file ? File::stat::lstat($file) : File::stat::stat($file);
    if ( !$stat ) {
      if ( !$opt->nodelete ) {
        push( @to_delete, $file );
      }
      next;
    }

    $cache{$file} = $attrs;
  }
  &_log_info('Cache read took: ' . sprintf( "%.9f", ( time - $t ) ) . "s");

  close($fh);
  undef($fh);

  if ( !$opt->nodelete && @to_delete ) {
    _delete_files(@to_delete);
  }

  return %cache;
}

sub _filename_cache_version {
  join( '.', shift, 'version' );
}

sub _update_cache_version {
  my $filename = shift;
  my $fh = IO::File->new( $filename, 'w', ':unix' )
    or die "Cannot open $filename";
  print $fh $VERSION;
}

sub _read_cache_version {
  my $filename = shift;
  return qv(0) unless -r $filename;
  my $content = do { local ( @ARGV, $/ ) = $filename; <> };
  return $content if qv($content)->is_qv;
  return qv(0);
}

sub _write_cache {
  my (%cache)            = @_;
  my $t                  = time;
  my $cache_file         = &_make_control_file('cache');
  my $cache_file_version = &_filename_cache_version($cache_file);
  &_update_cache_version($cache_file_version);

  open( my $fh, '>:unix', $cache_file )
    or die "Cannot open $cache_file";

  print {$fh}
    map {
    my $attrs = $cache{$_};
    Encode::encode_utf8( join( q{,}, $_, @$attrs ) . "\n" );
    }
    keys %cache;

  # $cache_file->close;
  &_log_info('* Cache write took: '. sprintf( "%.9f", ( time - $t ) ) . "s");
}

sub lock {
  my ($fh) = @_;
  flock( $fh, LOCK_EX ) or die "Cannot lock file - $!\n";
  seek( $fh, 0, SEEK_END ) or die "Cannot seek - $!\n";
}

sub unlock {
  my ($fh) = @_;
  flock( $fh, LOCK_UN ) or die "Cannot unlock file - $!\n";
}

sub _stage_file {
  join( '/', $stage_dir, md5_hex( $node_key . $partner_key . $path . shift ) );
}

sub _link_to_stage {
  my $file       = shift;
  my $stage_file = _stage_file($file);
  copy( $file, $stage_file ) or die "Copy failed: $!";
  return $stage_file;
}

